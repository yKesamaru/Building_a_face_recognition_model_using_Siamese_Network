# 


## 対象とする読者
- MNIST（手書き数字認識）の次に何をしていいかわからない方
- 顔認識に興味がある方
- 画像認識の実践的なスキルを身につけたい方
- AIに興味がある高校生や大学生

## はじめに: 挑戦への動機づけ
手書き数字（0〜9）を識別するプログラム「MNIST」は、機械学習、特に深層学習の入門として有名で、機械学習の「Hello World」と呼ばれるほど広く利用されています。電子工作で例えると、ラズベリーパイの「Lチカ」に相当すると思います。

それで次は何をしたらいいでしょう？

わたしの推しは、ずばり「顔認識」です。

え？YouTubeに色々あるって？いえいえ。ここだけの話ですが、あれって全部、既にあるサービス・ライブラリの利用方法を解説してるだけなんです。だいたい3つのパターンな感じです。

1. Pythonのライブラリを使用した顔認識の実装パターン
   - face-recognitionライブラリを使用した顔認識の実装方法を解説
   - OpenCV、Dlib、face_recognitionなどのライブラリを使用した顔認識の実装方法の紹介

2. 特定のフレームワークを活用したパターン
   - PythonライブラリのStreamlitとAzure Face APIを組み合わせた顔検出アプリ作成解説
   - FACE01という顔認識フレームワークを使用した動画からの顔画像データ抽出方法

3. 顔認識サービスのクラウドAPIを利用するパターン
   - Google Cloud Vision APIを使用した顔検出機能の紹介: 動画内の顔の検出、境界ボックスの生成、顔の属性検出。
   - Microsoft Face API、Amazon Rekognition、IBM Watson Visual Recognition APIなどの、クラウドサービスの顔認識機能の比較と使用方法の紹介

これら全てに共通しているのは、**既にある学習済みモデルを利用している**、ということなんです。

でもMNISTでは手書き数字を認識するための**学習モデルをつくるコードを作り、学習させて、検証まで**やりました。

MNISTの場合は0〜9までの10クラス分類でした。MNISTの次に挑戦するなら、クラス数を増やした学習です。

CIFAR-100, Fashion-MNIST, Kuzushiji-Kanjiなどありますが、どうせなら実用的なものをやりたいですよね。

オープンセット分類をご存知ですか？

不良品の画像診断なんかに用いられるのですが、一言で言えば「クラス数無制限の分類」です。この分類は**工場や農家で実際に使われている**のです。

だから、**MNISTを卒業したら、オープンセット分類をやりましょう！**

とはいえ、画像データセットを用意するのはなかなか大変です。不良品のネジとか形の崩れたきゅうりの画像を沢山集めるのは現実的ではありません。

そこで偉大な先人たちは

- 大好きなアイドルの顔分類
- ポケモンの分類

などを「自らの修練」として選んだのです[^1]。
[^1]: 中にはごついお兄さんのデータセットを選んでしまい、やらなければよかったと撃沈した勇者もいました。

しかしそうした偉人たちはさらに修練を進め、今ではより高みに登ってしまったがゆえ、今だったらこういうコードを書くのに、という状況に対応していません。

2024年、いや、2025年に是非挑戦してほしいオープンセット分類。イマドキのやり方で挑戦しませんか？

この記事を読み、この記事のコードを使えば、学習用のコードを動作させ、出来上がったモデルを検証することが出来ます。

さらに前処理済みの顔データセットも付属します！！スクレイピングや前処理の必要が無いのは嬉しいですね[^3}⭐️

[^3]: もちろん、これらを使って商用利用したり配布したらダメですよ！

もちろん顔認証だけでなく、様々な画像分類に使うことが出来ます。

## 顔認証について小難しい〇〇をチラ見する
< 時間のない方はここを飛ばしてください。 >

顔認証というのはオープンセット分類だ、というのは先述しました。実際に現場で使える技術を学ぼう！という動機も書きました。

でもですね、実務で使えるレベルって小難しい沢山のことに対応しなきゃいけないんです。MNISTの次に挑戦するなら、そういった小難しい〇〇はすっ飛ばしたいですよね。

例えば照明、カメラの収差。レンズ選びと撮影距離によって、被写体は全く別物くらいに写ります。[ワールド座標系・カメラ座標系](https://zenn.dev/ykesamaru/articles/b9a1efa47b30b1)とか。こういうのは実務に向き合う時に覚えればいいことです。[^2]
[^2]: 拙著記事を参考文献リストに入れておきます。ご興味のある方は読んでみてね。

ただ、顔データセットを作る時に、同じ人物（同じクラス）なのにどうしてこんなに写りが違うのだろう、と思ったら調べてみてください。

![](https://tokai-kaoninsho.com/wp-content/uploads/2020/09/%E3%83%AC%E3%83%B3%E3%82%BA%E3%81%AB%E3%82%88%E3%82%8B%E8%A6%8B%E3%81%88%E6%96%B9%E3%81%AE%E9%81%95%E3%81%84-1.gif)

小難しい話はとばしたいところですが、学習モデルを作成するコードを書くにあたって、これはどんな目的のコードなのか？という点は押さえておきたいところです。

それは**認証にはスコープがあるということ**です。どんな規模感で、どんなスコープを対象に使うか、ということですね。そういうのが違うと、求められる学習モデルが違ってくるので、必然的に学習コードが違ってくるわけです。

### 小規模タスク
特定環境、例えば企業内の認証システムなどでは、高精度な1対1認証が求められます。私感ですが、最もよく使用されるのは指紋認証のように感じます。スマホのロック解除にも使われますね。企業内の顔認証システム構築では一般的にこのスコープに含まれます。

このようなスコープで使われるのは1対1モードの認証です。

![https//jp.fujitsu.com/platform/pc/product/related/security/auth.html](https://raw.githubusercontent.com/yKesamaru/Building_a_face_recognition_model_using_Siamese_Network/refs/heads/master/assets/shimon_esprimo2.jpg)

### 中規模タスク
公共の顔認識がこのスコープに含まれます。防犯カメラの映像解析やネットを対象にしたリサーチなどですね。あるいはコンサート会場の顔認証ゲートなんかです。

オープンソースで開発されている[FACE01](https//github.com/yKesamaru/FACE01_DEV)や[その学習済みモデル](https//github.com/yKesamaru/FACE01_trained_models)はここに含まれます。

### 大規模タスク
全人種を対象にした顔認証システムがここに含まれます。航空機発着ゲートなんかに使われています。

### 【1対1モード】と【1対多モード】の違い
先程のスコープに対応させるため、認識システムには、大きく分けて2つのモードがあります。それぞれの特徴と使用シーンを見てみましょう。

#### 【1対1モード】
「1対1」モードは、2つの顔画像を比較し、それらが同一人物かどうかを判定する手法です。このモードは、**ペア単位**の認証が求められるタスクに使われます。

- 類似度計算が中心
- ペア単位での判定（学習が比較的容易）
- データベースとの照合も行わないため、処理が簡潔。

通常、顔認証システムと呼ばれる多くが「1対1」モードであるといえます。正解データとの突き合わせをすればよいだけなので、（ちゃんとやれば）比較的簡単に精度を稼げます。

#### 【1対多モード】
「1対多」モードは、1つの顔画像をデータベースと照合し、最も一致する人物を特定する方法です。監視カメラシステムや公共施設のアクセス制御など、大量の顔データを管理するシステムで一般的に使用されます。

- データベース全体と照合するため、計算コストが高い
- 顔IDの分類タスクとして設計される（学習が難しい）
- 複数の人物から候補を絞り込むことが前提

先ほど紹介した[FACE01](https//github.com/yKesamaru/FACE01_DEV)や[その学習済みモデル](https//github.com/yKesamaru/FACE01_trained_models)はここに含まれます。

「1対多」モードは「1対1」モードを包含します。

$$1\text{:}1\ \text{モード} \subseteq 1\text{:}\text{N}\ \text{モード}$$

なので1対多モード用に作られた学習モデルは1対1モードでも問題無く使用可能です。


| 特徴              | 1対1モード                                   | 1対多モード                                   |
|-------------------|--------------------------------------------|--------------------------------------------|
| **概要**           | 特定の個人の顔データと入力画像を比較する。       | 入力画像をデータベース内の複数の顔データと照合する。 |
| **特徴**       | 比較対象が1人のみで誤認識が少ない。 | 誤認識を防ぐ高い精度が必要。 |
| **用途**          | IDカードやICカードによる本人認証。             | 監視カメラや公共施設での人物特定。             |

## ネットワークの設計
さて、ここからは実際に学習用のコードを設計していきましょう。

先程の小難しい話に、1対1モードと1対多モードの話がありましたが、ここでは設計が単純な1対1モードのコードを設計します。

ネットワークはSiamese Networkを用います。Siamese Networkを初めて目にする方は、先に[はやぶさの技術ノート: 【深層距離学習】Siamese NetworkとContrastive Lossを徹底解説](https://cpp-learning.com/siamese-network/)を読むと良いでしょう。とてもわかり易くまとまった良記事です。

誤解を恐れずに言えば、Siamese Networkとは2つの入力を受け取り、それらの類似度を学習する構造のことです。その構造の中身をどうするかは設計者が自由に取捨選択します。シンプルな考え方なので、実装も容易です。

![](https://raw.githubusercontent.com/yKesamaru/Building_a_face_recognition_model_using_Siamese_Network/refs/heads/master/assets/2024-12-13-14-27-59.png)

それではバックボーンや損失関数、オプティマイザ・スケジューラを決めていきましょう。

ここではよく使われるものを紹介し、最後にどれを使うか説明します。

### Siamese Networkにおけるバックボーン
バックボーンとしてEfficientNetV2やResNetなどを利用します。これらは、入力画像から特徴量を抽出（入力データを低次元の特徴ベクトルに変換）するのが仕事です。扱いやすいのはなんと言ってもモバイル系のネットワークです。それについては拙著の[モバイル学習モデルの俯瞰: MobileNetV1からEfficientNetV2まで](https://zenn.dev/ykesamaru/articles/29e128e65e8a11)をご参照ください。

モデルの大きさと学習の効率性からtimmから提供されている[EfficientNetV2のB0事前学習済みモデル](https://github.com/openvinotoolkit/open_model_zoo/blob/master/models/public/efficientnet-v2-b0/README.md)を採用します。この事前学習済みモデルはImageNetデータセットでトレーニングされています。これを転移学習することで、任意の画像分類に利用できるわけです。


## よく使われる損失関数
Siamese Networkでは、以下のような損失関数をよく使います。

### Contrastive Loss
Siamese Networkにおいて最も一般的です。

$$L = \frac{1}{2} \left( Y D^2 + (1 - Y) \max(\text{margin} - D, 0)^2 \right)
$$

### Triplet Loss
Triplet Lossは、アンカー、ポジティブ、ネガティブの3つの入力を用いて類似性を最適化します。この損失関数は、埋め込み空間での識別性を向上させる効果があります。[dlib](http://dlib.net/)の学習済みモデルはこのトリプレットロスを採用しています。

$$L = \max(D(a, p) - D(a, n) + \text{margin}, 0)$$

- $D(a, p)$: アンカー ($a$) とポジティブ ($p$) サンプル間の距離。
- $D(a, n)$: アンカー ($a$) とネガティブ ($n$) サンプル間の距離。
- $\text{margin}$: ポジティブとネガティブサンプルの距離の差を保証するためのマージン。

### Binary Cross-Entropy Loss
2つの入力が同一か否かを確率的に予測します。

$$L = - \frac{1}{N} \sum_{i=1}^N \left[ y_i \log(\hat{y}_i) + (1 - y_i) \log(1 - \hat{y}_i) \right]$$

- $y_i$: 実際のラベル（0または1）。
- $\hat{y}_i$: モデルの予測確率（0〜1）。
- $N$: サンプル数。

これらの中で、ここでは顔認証タスクに定評のあるTriplet Lossを採用します。Triplet lossについては拙著[顔認証が顔を識別する仕組み](https://tokai-kaoninsho.com/%E3%82%B3%E3%83%A9%E3%83%A0/%E9%A1%94%E8%AA%8D%E8%A8%BC%E3%81%8C%E9%A1%94%E3%82%92%E8%AD%98%E5%88%A5%E3%81%99%E3%82%8B%E4%BB%95%E7%B5%84%E3%81%BF/)をご参照ください。

![](https://raw.githubusercontent.com/yKesamaru/Building_a_face_recognition_model_using_Siamese_Network/refs/heads/master/assets/face_recognition_opencv_triplet.jpg)

## 必要なID数（クラス数）の見積もり
データセットについて考えましょう。設計上、どこに気をつければよいのでしょうか？
### クラス数（ID数）よりペア数が重要
通常、何も考えなければ、データセットのクラス数（ID）は多ければ多いほどよいとされます。ただ、そこにさけるパワーは有限ですし、そもそも画像を揃えられないこともしばしばです。

1対1認証では、IDの数そのものよりも生成可能なペアの数が重要です。

ですから人で考えれば、5枚ずつ1万人分の画像を集めるよりも、100枚ずつ100人分の画像を集めたほうがよいのです。
（だから1対1モードを選んだのですが）

データセットは人数分、名前をフォルダ名にしてまとめればよいでしょう。

ペア数のペアとは、以下のような考え方です。

- **同一ID内（Positiveペア）**
  - 同一人物間でのペア。
- **異なるID間（Negativeペア）**
  - 異なる人物間でのペア。

このペア数が、1対1認証では重要である、ということです。

また、推奨されるID数の目安も知っておくと良いでしょう。

- **小規模タスク** 1000ID。
- **中規模タスク** 1000～2000ID。
- **大規模タスク** 5000ID以上。

その他、ペアの多様性や各IDに含まれる画像数がモデルの性能に影響を与えるため、顔画像データセットの質が重要です。（コレ自体でいくらでも精度が変わってしまう。。）
[付属の顔データセット](https://github.com/yKesamaru/Building_a_face_recognition_model_using_Siamese_Network)は前処理済みです。
















## 参考文献リスト
- 拙著記事
  - [カメラキャリブレーションのABC: 知っておきたい基本](https://tokai-kaoninsho.com/%e3%82%b3%e3%83%a9%e3%83%a0/%e3%82%ab%e3%83%a1%e3%83%a9%e3%82%ad%e3%83%a3%e3%83%aa%e3%83%96%e3%83%ac%e3%83%bc%e3%82%b7%e3%83%a7%e3%83%b3%e3%81%aeabc-%e7%9f%a5%e3%81%a3%e3%81%a6%e3%81%8a%e3%81%8d%e3%81%9f%e3%81%84%e5%9f%ba/)
  - [レンズの歪曲収差と対応方法](https://tokai-kaoninsho.com/%e3%82%b3%e3%83%a9%e3%83%a0/%e3%83%ac%e3%83%b3%e3%82%ba%e3%81%ae%e6%ad%aa%e6%9b%b2%e5%8f%8e%e5%b7%ae%e3%81%a8%e5%af%be%e5%bf%9c%e6%96%b9%e6%b3%95/)
  - [日本人顔認識のための新たな学習モデルを作成 ~ `EfficientNetV2`ファインチューニング ~](https://zenn.dev/ykesamaru/articles/bc74ec27925896)
  - [モバイル学習モデルの俯瞰: MobileNetV1からEfficientNetV2まで](https://zenn.dev/ykesamaru/articles/29e128e65e8a11)
- 拙作リポジトリ
  - [FACE01 開発リポジトリ](https://github.com/yKesamaru/FACE01_DEV)
  - [FACE01 学習済みモデル](https://github.com/yKesamaru/FACE01_trained_models)
- その他
  - [Siamese NetworkとContrastive Lossを徹底解説 - はやぶさの技術ノート](https://cpp-learning.com/siamese-network/)
  - [Siamese Networkの提案論文（NIPS1993）](https://papers.nips.cc/paper/1993/file/288cc0ff022877bd3df94bc9360b9c5d-Paper.pdf)
  - [PyTorch Metric Learning](https://kevinmusgrave.github.io/pytorch-metric-learning/)
  - [全ての学習率スケジューリングを過去にするOptimizer - DeNA技術記事](https://zenn.dev/dena/articles/6f04641801b387)

