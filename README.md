# Siamese Networkã‚’ç”¨ã„ãŸé¡”èªè­˜ãƒ¢ãƒ‡ãƒ«ã®æ§‹ç¯‰

## ã¯ã˜ã‚ã«
é¡”èªè­˜ã‚·ã‚¹ãƒ†ãƒ ã‚’æ§‹ç¯‰ã™ã‚‹éš›ã«ã€**ã€Œ1å¯¾1ã€ãƒ¢ãƒ¼ãƒ‰ã¨ã€Œ1å¯¾å¤šã€ãƒ¢ãƒ¼ãƒ‰**ã¨ã„ã†2ã¤ã®ä¸»è¦ãªæ‰‹æ³•ãŒã‚ã‚Šã¾ã™ã€‚æœ¬è¨˜äº‹ã§ã¯ã€ç‰¹ã«ã€Œ1å¯¾1ã€ãƒ¢ãƒ¼ãƒ‰ã«ç„¦ç‚¹ã‚’å½“ã¦ã€**Siamese Networkï¼ˆã‚·ãƒ£ãƒ ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ï¼‰ã‚’ç”¨ã„ãŸé¡”èªè­˜ãƒ¢ãƒ‡ãƒ«ã®è¨­è¨ˆã¨æ§‹ç¯‰**ã«ã¤ã„ã¦è©³ã—ãè§£èª¬ã—ã€æœ€å¾Œã«å®Ÿè¡Œå¯èƒ½ãªã‚³ãƒ¼ãƒ‰ã‚’ç´¹ä»‹ã—ã€10ã‚¯ãƒ©ã‚¹å­¦ç¿’ã•ã›ãŸå¾Œã®AUCã‚¹ã‚³ã‚¢ã¨ROCæ›²ç·šã‚’ãƒ—ãƒ­ãƒƒãƒˆã—ã¾ã™ã€‚

![](https://raw.githubusercontent.com/yKesamaru/Building_a_face_recognition_model_using_Siamese_Network/refs/heads/master/assets/eye-catch.png)

## é¡”èªè¨¼ã‚¿ã‚¹ã‚¯ã®ã‚¹ã‚³ãƒ¼ãƒ—
ä¸€å£ã«é¡”èªè¨¼ã‚·ã‚¹ãƒ†ãƒ ã¨ã„ã£ã¦ã‚‚ã€ã©ã®ã‚ˆã†ãªã‚·ãƒ¼ãƒ³ã§ä½¿ã‚ã‚Œã‚‹ã®ã‹ã®æƒ³å®šã«ã‚ˆã£ã¦ã€ã‚·ã‚¹ãƒ†ãƒ æ§‹æˆãŒç•°ãªã£ã¦ãã¾ã™ã€‚å…·ä½“çš„ã«ã¯ã€ä½¿ç”¨ã•ã‚Œã‚‹å­¦ç¿’æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ãŒç•°ãªã£ã¦ãã‚‹ã€ã¨ã„ã†ã“ã¨ã§ã™ã€‚

### å°è¦æ¨¡ã‚¿ã‚¹ã‚¯
ç‰¹å®šç’°å¢ƒã€ä¾‹ãˆã°ä¼æ¥­å†…ã®èªè¨¼ã‚·ã‚¹ãƒ†ãƒ ãªã©ã§ã¯ã€é«˜ç²¾åº¦ãª1å¯¾1èªè¨¼ãŒæ±‚ã‚ã‚‰ã‚Œã¾ã™ã€‚ç§æ„Ÿã§ã™ãŒã€æœ€ã‚‚ã‚ˆãä½¿ç”¨ã•ã‚Œã‚‹ã®ã¯æŒ‡ç´‹èªè¨¼ã®ã‚ˆã†ã«æ„Ÿã˜ã¾ã™ã€‚ã‚¹ãƒãƒ›ã®ãƒ­ãƒƒã‚¯è§£é™¤ã«ã‚‚ä½¿ã‚ã‚Œã¾ã™ã­ã€‚ä¼æ¥­å†…ã®é¡”èªè¨¼ã‚·ã‚¹ãƒ†ãƒ æ§‹ç¯‰ã§ã¯ä¸€èˆ¬çš„ã«ã“ã®ã‚¹ã‚³ãƒ¼ãƒ—ã«å«ã¾ã‚Œã¾ã™ã€‚

ã“ã®ã‚ˆã†ãªã‚¹ã‚³ãƒ¼ãƒ—ã§ä½¿ã‚ã‚Œã‚‹ã®ã¯1å¯¾1èªè¨¼ã§ã™ã€‚

![https//jp.fujitsu.com/platform/pc/product/related/security/auth.html](https://raw.githubusercontent.com/yKesamaru/Building_a_face_recognition_model_using_Siamese_Network/refs/heads/master/assets/shimon_esprimo2.jpg)

### ä¸­è¦æ¨¡ã‚¿ã‚¹ã‚¯
å…¬å…±ã®é¡”èªè­˜ãŒã“ã®ã‚¹ã‚³ãƒ¼ãƒ—ã«å«ã¾ã‚Œã¾ã™ã€‚é˜²çŠ¯ã‚«ãƒ¡ãƒ©ã®æ˜ åƒè§£æã‚„ãƒãƒƒãƒˆã‚’å¯¾è±¡ã«ã—ãŸãƒªã‚µãƒ¼ãƒãªã©ã§ã™ã­ã€‚

ã‚ªãƒ¼ãƒ—ãƒ³ã‚½ãƒ¼ã‚¹ã§é–‹ç™ºã•ã‚Œã¦ã„ã‚‹[FACE01](https//github.com/yKesamaru/FACE01_DEV)ã‚„[ãã®å­¦ç¿’æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«](https//github.com/yKesamaru/FACE01_trained_models)ã¯ã“ã“ã«å«ã¾ã‚Œã¾ã™ã€‚

### å¤§è¦æ¨¡ã‚¿ã‚¹ã‚¯
å…¨äººç¨®ã‚’å¯¾è±¡ã«ã—ãŸé¡”èªè¨¼ã‚·ã‚¹ãƒ†ãƒ ãŒã“ã“ã«å«ã¾ã‚Œã¾ã™ã€‚

## ã€1å¯¾1ãƒ¢ãƒ¼ãƒ‰ã€‘ã¨ã€1å¯¾å¤šãƒ¢ãƒ¼ãƒ‰ã€‘ã®é•ã„

é¡”èªè­˜ã‚·ã‚¹ãƒ†ãƒ ã«ã¯ã€å…ˆç¨‹ã®ã‚¹ã‚³ãƒ¼ãƒ—ã«å¯¾å¿œã•ã›ã‚‹ãŸã‚ã€å¤§ããåˆ†ã‘ã¦2ã¤ã®ãƒ¢ãƒ¼ãƒ‰ãŒã‚ã‚Šã¾ã™ã€‚ãã‚Œãã‚Œã®ç‰¹å¾´ã¨ä½¿ç”¨ã‚·ãƒ¼ãƒ³ã‚’è¦‹ã¦ã¿ã¾ã—ã‚‡ã†ã€‚

### ã€1å¯¾1ãƒ¢ãƒ¼ãƒ‰ã€‘
ã€Œ1å¯¾1ã€ãƒ¢ãƒ¼ãƒ‰ã¯ã€2ã¤ã®é¡”ç”»åƒã‚’æ¯”è¼ƒã—ã€ãã‚Œã‚‰ãŒåŒä¸€äººç‰©ã‹ã©ã†ã‹ã‚’åˆ¤å®šã™ã‚‹æ‰‹æ³•ã§ã™ã€‚ã“ã®ãƒ¢ãƒ¼ãƒ‰ã¯ã€**ãƒšã‚¢å˜ä½**ã®èªè¨¼ãŒæ±‚ã‚ã‚‰ã‚Œã‚‹ã‚¿ã‚¹ã‚¯ã«ä½¿ã‚ã‚Œã¾ã™ã€‚

- é¡ä¼¼åº¦è¨ˆç®—ãŒä¸­å¿ƒ
- ãƒšã‚¢å˜ä½ã§ã®åˆ¤å®šï¼ˆå­¦ç¿’ãŒæ¯”è¼ƒçš„å®¹æ˜“ï¼‰
- ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã¨ã®ç…§åˆã‚‚è¡Œã‚ãªã„ãŸã‚ã€å‡¦ç†ãŒç°¡æ½”ã€‚

é€šå¸¸ã€é¡”èªè¨¼ã‚·ã‚¹ãƒ†ãƒ ã¨å‘¼ã°ã‚Œã‚‹å¤šããŒã€Œ1å¯¾1ã€ãƒ¢ãƒ¼ãƒ‰ã§ã‚ã‚‹ã¨ã„ãˆã¾ã™ã€‚æ­£è§£ãƒ‡ãƒ¼ã‚¿ã¨ã®çªãåˆã‚ã›ã‚’ã™ã‚Œã°ã‚ˆã„ã ã‘ãªã®ã§ã€ï¼ˆã¡ã‚ƒã‚“ã¨ã‚„ã‚Œã°ï¼‰æ¯”è¼ƒçš„ç°¡å˜ã«ç²¾åº¦ã‚’ç¨¼ã’ã¾ã™ã€‚

### ã€1å¯¾å¤šãƒ¢ãƒ¼ãƒ‰ã€‘
ã€Œ1å¯¾å¤šã€ãƒ¢ãƒ¼ãƒ‰ã¯ã€1ã¤ã®é¡”ç”»åƒã‚’ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã¨ç…§åˆã—ã€æœ€ã‚‚ä¸€è‡´ã™ã‚‹äººç‰©ã‚’ç‰¹å®šã™ã‚‹æ–¹æ³•ã§ã™ã€‚ç›£è¦–ã‚«ãƒ¡ãƒ©ã‚·ã‚¹ãƒ†ãƒ ã‚„å…¬å…±æ–½è¨­ã®ã‚¢ã‚¯ã‚»ã‚¹åˆ¶å¾¡ãªã©ã€å¤§é‡ã®é¡”ãƒ‡ãƒ¼ã‚¿ã‚’ç®¡ç†ã™ã‚‹ã‚·ã‚¹ãƒ†ãƒ ã§ä¸€èˆ¬çš„ã«ä½¿ç”¨ã•ã‚Œã¾ã™ã€‚

- ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹å…¨ä½“ã¨ç…§åˆã™ã‚‹ãŸã‚ã€è¨ˆç®—ã‚³ã‚¹ãƒˆãŒé«˜ã„
- é¡”IDã®åˆ†é¡ã‚¿ã‚¹ã‚¯ã¨ã—ã¦è¨­è¨ˆã•ã‚Œã‚‹ï¼ˆå­¦ç¿’ãŒé›£ã—ã„ï¼‰
- è¤‡æ•°ã®äººç‰©ã‹ã‚‰å€™è£œã‚’çµã‚Šè¾¼ã‚€ã“ã¨ãŒå‰æ

å…ˆã»ã©ç´¹ä»‹ã—ãŸ[FACE01](https//github.com/yKesamaru/FACE01_DEV)ã‚„[ãã®å­¦ç¿’æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«](https//github.com/yKesamaru/FACE01_trained_models)ã¯ã“ã“ã«å«ã¾ã‚Œã¾ã™ã€‚

ã€Œ1å¯¾å¤šã€ãƒ¢ãƒ¼ãƒ‰ã¯ã€Œ1å¯¾1ã€ãƒ¢ãƒ¼ãƒ‰ã‚’åŒ…å«ã—ã¾ã™ã€‚

$$1\text{:}1\ \text{ãƒ¢ãƒ¼ãƒ‰} \subseteq 1\text{:}\text{N}\ \text{ãƒ¢ãƒ¼ãƒ‰}$$

ãªã®ã§1å¯¾å¤šãƒ¢ãƒ¼ãƒ‰ç”¨ã«ä½œã‚‰ã‚ŒãŸå­¦ç¿’ãƒ¢ãƒ‡ãƒ«ã¯1å¯¾1ãƒ¢ãƒ¼ãƒ‰ã§ã‚‚å•é¡Œç„¡ãä½¿ç”¨å¯èƒ½ã§ã™ã€‚


| ç‰¹å¾´              | 1å¯¾1ãƒ¢ãƒ¼ãƒ‰                                   | 1å¯¾å¤šãƒ¢ãƒ¼ãƒ‰                                   |
|-------------------|--------------------------------------------|--------------------------------------------|
| **æ¦‚è¦**           | ç‰¹å®šã®å€‹äººã®é¡”ãƒ‡ãƒ¼ã‚¿ã¨å…¥åŠ›ç”»åƒã‚’æ¯”è¼ƒã™ã‚‹ã€‚       | å…¥åŠ›ç”»åƒã‚’ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹å†…ã®è¤‡æ•°ã®é¡”ãƒ‡ãƒ¼ã‚¿ã¨ç…§åˆã™ã‚‹ã€‚ |
| **ç‰¹å¾´**       | æ¯”è¼ƒå¯¾è±¡ãŒ1äººã®ã¿ã§èª¤èªè­˜ãŒå°‘ãªã„ã€‚ | èª¤èªè­˜ã‚’é˜²ãé«˜ã„ç²¾åº¦ãŒå¿…è¦ã€‚ |
| **ç”¨é€”**          | IDã‚«ãƒ¼ãƒ‰ã‚„ICã‚«ãƒ¼ãƒ‰ã«ã‚ˆã‚‹æœ¬äººèªè¨¼ã€‚             | ç›£è¦–ã‚«ãƒ¡ãƒ©ã‚„å…¬å…±æ–½è¨­ã§ã®äººç‰©ç‰¹å®šã€‚             |


## Siamese Networkã¨ã¯ï¼Ÿ

### æ¦‚è¦
[Siamese Networkã¯1994å¹´ã«Bromleyã‚‰ã«ã‚ˆã£ã¦ææ¡ˆ](https//papers.nips.cc/paper/1993/file/288cc0ff022877bd3df94bc9360b9c5d-Paper.pdf?utm_source=chatgpt.com)ã•ã‚Œã¾ã—ãŸã€‚ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã¨æ›¸ã„ã¦ã‚ã‚Šã¾ã™ãŒã€ã‚‚ã£ã¨å¤§ã‚‚ã¨ã®ã€Œè€ƒãˆæ–¹ã€ã®ã‚ˆã†ãªã‚‚ã®ã§ã™ã€‚

![](https://raw.githubusercontent.com/yKesamaru/Building_a_face_recognition_model_using_Siamese_Network/refs/heads/master/assets/2024-12-13-14-23-15.png)

[ã¯ã‚„ã¶ã•ã®æŠ€è¡“ãƒãƒ¼ãƒˆ: ã€æ·±å±¤è·é›¢å­¦ç¿’ã€‘Siamese Networkã¨Contrastive Lossã‚’å¾¹åº•è§£èª¬](https://cpp-learning.com/siamese-network/)ãŒã¨ã¦ã‚‚ã‚ã‹ã‚Šæ˜“ã„ã§ã™ã€‚

ã“ã®ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã¯ã€2ã¤ã®å…¥åŠ›ã‚’å—ã‘å–ã‚Šã€ãã‚Œã‚‰ã®é¡ä¼¼åº¦ã‚’å­¦ç¿’ã™ã‚‹æ§‹é€ ã‚’æŒã£ã¦ã„ã¾ã™ã€‚

### ä¸»ãªç‰¹å¾´
Siamese Networkã¯ã€åŒä¸€æ§‹é€ ã®2ã¤ã®ã‚µãƒ–ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã§ç‰¹å¾´ã‚’æŠ½å‡ºã—ã€ãã®é¡ä¼¼æ€§ã‚’è¨ˆç®—ã™ã‚‹ã€ã¨ã„ã†è€ƒãˆæ–¹ã§ã™ã€‚ã‚·ãƒ³ãƒ—ãƒ«ãªè€ƒãˆæ–¹ãªã®ã§ã€å®Ÿè£…ã‚‚å®¹æ˜“ã§ã™ã€‚

![](https://raw.githubusercontent.com/yKesamaru/Building_a_face_recognition_model_using_Siamese_Network/refs/heads/master/assets/2024-12-13-14-27-59.png)

## Siamese Networkã«ãŠã‘ã‚‹ãƒãƒƒã‚¯ãƒœãƒ¼ãƒ³
Siamese Networkã¯ã€ãªã«ã‚’ãƒãƒƒã‚¯ãƒœãƒ¼ãƒ³ã«ã™ã‚‹ã‹ã§å®Ÿè£…ãŒå¤‰ã‚ã£ã¦ãã¾ã™ã€‚

EfficientNetV2ã‚„ResNetãªã©ã‚’åˆ©ç”¨ã™ã‚‹ã“ã¨ã§ã€å…¥åŠ›ç”»åƒã‹ã‚‰ç‰¹å¾´é‡ã‚’æŠ½å‡ºï¼ˆå…¥åŠ›ãƒ‡ãƒ¼ã‚¿ã‚’ä½æ¬¡å…ƒã®ç‰¹å¾´ãƒ™ã‚¯ãƒˆãƒ«ã«å¤‰æ›ï¼‰ã—ã¾ã™ã€‚

Siamese Networkã§ã¯ã€ãƒãƒƒã‚¯ãƒœãƒ¼ãƒ³ã§æŠ½å‡ºã•ã‚ŒãŸç‰¹å¾´ãƒ™ã‚¯ãƒˆãƒ«ã‚’æ¯”è¼ƒã—ã€å…¥åŠ›ãƒšã‚¢ã®é¡ä¼¼æ€§ã‚’åˆ¤å®šã—ã¾ã™ã€‚

## ã‚ˆãä½¿ã‚ã‚Œã‚‹æå¤±é–¢æ•°
Siamese Networkã§ã¯ã€ä»¥ä¸‹ã®ã‚ˆã†ãªæå¤±é–¢æ•°ã‚’ã‚ˆãä½¿ã„ã¾ã™ã€‚

### Contrastive Loss
Siamese Networkã«ãŠã„ã¦æœ€ã‚‚ä¸€èˆ¬çš„ã§ã™ã€‚

$$L = \frac{1}{2} \left( Y D^2 + (1 - Y) \max(\text{margin} - D, 0)^2 \right)
$$

### Triplet Loss
Triplet Lossã¯ã€ã‚¢ãƒ³ã‚«ãƒ¼ã€ãƒã‚¸ãƒ†ã‚£ãƒ–ã€ãƒã‚¬ãƒ†ã‚£ãƒ–ã®3ã¤ã®å…¥åŠ›ã‚’ç”¨ã„ã¦é¡ä¼¼æ€§ã‚’æœ€é©åŒ–ã—ã¾ã™ã€‚ã“ã®æå¤±é–¢æ•°ã¯ã€åŸ‹ã‚è¾¼ã¿ç©ºé–“ã§ã®è­˜åˆ¥æ€§ã‚’å‘ä¸Šã•ã›ã‚‹åŠ¹æœãŒã‚ã‚Šã¾ã™ã€‚[dlib](http://dlib.net/)ã®å­¦ç¿’æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ã¯ã“ã®ãƒˆãƒªãƒ—ãƒ¬ãƒƒãƒˆãƒ­ã‚¹ã‚’æ¡ç”¨ã—ã¦ã„ã¾ã™ã€‚

$$L = \max(D(a, p) - D(a, n) + \text{margin}, 0)$$

- $D(a, p)$: ã‚¢ãƒ³ã‚«ãƒ¼ ($a$) ã¨ãƒã‚¸ãƒ†ã‚£ãƒ– ($p$) ã‚µãƒ³ãƒ—ãƒ«é–“ã®è·é›¢ã€‚
- $D(a, n)$: ã‚¢ãƒ³ã‚«ãƒ¼ ($a$) ã¨ãƒã‚¬ãƒ†ã‚£ãƒ– ($n$) ã‚µãƒ³ãƒ—ãƒ«é–“ã®è·é›¢ã€‚
- $\text{margin}$: ãƒã‚¸ãƒ†ã‚£ãƒ–ã¨ãƒã‚¬ãƒ†ã‚£ãƒ–ã‚µãƒ³ãƒ—ãƒ«ã®è·é›¢ã®å·®ã‚’ä¿è¨¼ã™ã‚‹ãŸã‚ã®ãƒãƒ¼ã‚¸ãƒ³ã€‚

### Binary Cross-Entropy Loss
2ã¤ã®å…¥åŠ›ãŒåŒä¸€ã‹å¦ã‹ã‚’ç¢ºç‡çš„ã«äºˆæ¸¬ã—ã¾ã™ã€‚

$$L = - \frac{1}{N} \sum_{i=1}^N \left[ y_i \log(\hat{y}_i) + (1 - y_i) \log(1 - \hat{y}_i) \right]$$

- $y_i$: å®Ÿéš›ã®ãƒ©ãƒ™ãƒ«ï¼ˆ0ã¾ãŸã¯1ï¼‰ã€‚
- $\hat{y}_i$: ãƒ¢ãƒ‡ãƒ«ã®äºˆæ¸¬ç¢ºç‡ï¼ˆ0ã€œ1ï¼‰ã€‚
- $N$: ã‚µãƒ³ãƒ—ãƒ«æ•°ã€‚

## å¿…è¦ãªIDæ•°ï¼ˆã‚¯ãƒ©ã‚¹æ•°ï¼‰ã®è¦‹ç©ã‚‚ã‚Š

### IDæ•°ã‚ˆã‚Šãƒšã‚¢æ•°ãŒé‡è¦
1å¯¾1èªè¨¼ã§ã¯ã€IDã®æ•°ãã®ã‚‚ã®ã‚ˆã‚Šã‚‚ç”Ÿæˆå¯èƒ½ãªãƒšã‚¢ã®æ•°ãŒé‡è¦ã§ã™ã€‚
- **åŒä¸€IDå†…ï¼ˆPositiveãƒšã‚¢ï¼‰**
  - åŒä¸€äººç‰©é–“ã§ã®ãƒšã‚¢ã€‚
- **ç•°ãªã‚‹IDé–“ï¼ˆNegativeãƒšã‚¢ï¼‰**
  - ç•°ãªã‚‹äººç‰©é–“ã§ã®ãƒšã‚¢ã€‚

### æ¨å¥¨ã•ã‚Œã‚‹IDæ•°ã®ç›®å®‰
- **å°è¦æ¨¡ã‚¿ã‚¹ã‚¯** 1000IDã€‚
- **ä¸­è¦æ¨¡ã‚¿ã‚¹ã‚¯** 1000ï½2000IDã€‚
- **å¤§è¦æ¨¡ã‚¿ã‚¹ã‚¯** 5000IDä»¥ä¸Šã€‚

ãã®ä»–ã€ãƒšã‚¢ã®å¤šæ§˜æ€§ã‚„å„IDã«å«ã¾ã‚Œã‚‹ç”»åƒæ•°ãŒãƒ¢ãƒ‡ãƒ«ã®æ€§èƒ½ã«å½±éŸ¿ã‚’ä¸ãˆã‚‹ãŸã‚ã€é¡”ç”»åƒãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®è³ªãŒé‡è¦ã§ã™ã€‚ï¼ˆã‚³ãƒ¬è‡ªä½“ã§ã„ãã‚‰ã§ã‚‚ç²¾åº¦ãŒå¤‰ã‚ã£ã¦ã—ã¾ã†ã€‚ã€‚ï¼‰

## ã‚ªãƒ—ãƒ†ã‚£ãƒã‚¤ã‚¶ã¨ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ©ã®é¸æŠ
å­¦ç¿’ã‚’ã‚„ã£ã¦ã„ã‚‹æ–¹ã€…ã ã¨ã€ã€Œã„ã¤ã‚‚ã‚³ãƒ¬ã€ã¨ã„ã†çµ„ã¿åˆã‚ã›ãŒã‚ã‚‹ã‚‚ã®ã§ã™ã€‚ã‚ãŸã—ã®æ¨ã—ã¯ç‰¹ã«ç„¡ã„ã®ã§ã™ãŒã€ã‚ˆãè¦‹ã‹ã‘ã‚‹çµ„ã¿åˆã‚ã›ã‚’è¨˜è¼‰ã—ã¾ã™ã€‚ç°¡å˜ã«èª¬æ˜ã‚’ã¤ã‘ã¾ã™ãŒã€çµå±€ã€Œè¿‘ãã«ã„ã‚‹è©³ã—ã„äººãŒä½¿ã£ã¦ã‚‹ã®ã‚’ä½¿ãˆã€ãŒå¤šåˆ†æ­£ã—ã„ã§ã™ã€‚

### Adam + CosineAnnealingLR
- **é©ç”¨ã‚·ãƒ¼ãƒ³**
   - åˆæœŸå®Ÿè£…ã‚„æ±ç”¨çš„ãªå­¦ç¿’ã‚¿ã‚¹ã‚¯ã€‚
- **ç‰¹å¾´**
  - Adamã®å®‰å®šã—ãŸåæŸæ€§èƒ½ã¨ã€CosineAnnealingLRã®æŸ”è»Ÿãªå­¦ç¿’ç‡èª¿æ•´ã‚’çµ„ã¿åˆã‚ã›ãŸæ§‹æˆã€‚
  - å­¦ç¿’ã®ä¸­ç›¤ã§å­¦ç¿’ç‡ã‚’å¾ã€…ã«ä¸‹ã’ã€åæŸã‚’ã‚¹ãƒ ãƒ¼ã‚ºã«ã™ã‚‹ã€‚
- **ãƒ¡ãƒªãƒƒãƒˆ**
  - èª¿æ•´ãŒå°‘ãªãã¦æ¸ˆã¿ã€åºƒç¯„ãªã‚¿ã‚¹ã‚¯ã§å®‰å®šã—ãŸæ€§èƒ½ã‚’ç™ºæ®ã€‚

### AdamW + ReduceLROnPlateau
- **é©ç”¨ã‚·ãƒ¼ãƒ³**
   - å¤§è¦æ¨¡ãƒ¢ãƒ‡ãƒ«ã‚„éå­¦ç¿’ãŒæ‡¸å¿µã•ã‚Œã‚‹å ´åˆã€‚
- **ç‰¹å¾´**
  - AdamWãŒL2æ­£å‰‡åŒ–ã§éå­¦ç¿’ã‚’æŠ‘åˆ¶ã—ã€ReduceLROnPlateauãŒå­¦ç¿’ã®åœæ»æ™‚ã«å‹•çš„ã«å­¦ç¿’ç‡ã‚’èª¿æ•´ã€‚
- **ãƒ¡ãƒªãƒƒãƒˆ**
  - ãƒ¢ãƒ‡ãƒ«ã®å®‰å®šæ€§ã¨ç²¾åº¦å‘ä¸Šã‚’ä¸¡ç«‹ã§ãã‚‹ã€‚
  - æ¤œè¨¼æå¤±ãŒæ”¹å–„ã—ãªã„ã‚¿ã‚¤ãƒŸãƒ³ã‚°ã§è‡ªå‹•çš„ã«å­¦ç¿’ç‡ã‚’èª¿æ•´ã€‚

### SGD + StepLR
- **é©ç”¨ã‚·ãƒ¼ãƒ³**
   - å¤§è¦æ¨¡ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚„å¾®èª¿æ•´ãŒå¿…è¦ãªå ´åˆã€‚
- **ç‰¹å¾´**
  - SGDã«ã‚ˆã‚‹ã‚·ãƒ³ãƒ—ãƒ«ã§è¨ˆç®—åŠ¹ç‡ã®è‰¯ã„æ›´æ–°ã¨ã€StepLRã«ã‚ˆã‚‹æ®µéšçš„ãªå­¦ç¿’ç‡æ¸›å°‘ã‚’çµ„ã¿åˆã‚ã›ã€‚
- **ãƒ¡ãƒªãƒƒãƒˆ**
  - é•·æœŸé–“ã®å­¦ç¿’ã‚„å¤§è¦æ¨¡ãƒ‡ãƒ¼ã‚¿ã§ã®ãƒ¢ãƒ‡ãƒ«æ”¹å–„ã«åŠ¹æœçš„ã€‚

### Ranger + ExponentialLR
- **é©ç”¨ã‚·ãƒ¼ãƒ³**
   - å‹¾é…ã®å¤‰å‹•ãŒæ¿€ã—ã„å ´åˆã‚„å­¦ç¿’ãŒä¸å®‰å®šãªå ´åˆã€‚
- **ç‰¹å¾´**
  - RAdamã¨Lookaheadã‚’çµ„ã¿åˆã‚ã›ãŸRangerãŒæ»‘ã‚‰ã‹ãªåæŸã‚’æä¾›ã—ã€ExponentialLRãŒå­¦ç¿’ç‡ã‚’æŒ‡æ•°é–¢æ•°çš„ã«æ¸›å°‘ã•ã›ã‚‹ã€‚
- **ãƒ¡ãƒªãƒƒãƒˆ**
  - ç‰¹ã«å­¦ç¿’åˆæœŸã®ä¸å®‰å®šæ€§ã‚’æŠ‘ãˆã¤ã¤ã€å¾ŒåŠã§ã®åæŸã‚’ã‚¹ãƒ ãƒ¼ã‚ºã«ã™ã‚‹ã€‚

### [schedule_free](https://github.com/facebookresearch/schedule_free)
ã€Œ[å…¨ã¦ã®å­¦ç¿’ç‡ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒªãƒ³ã‚°ã‚’éå»ã«ã™ã‚‹Optimizer](https://zenn.dev/dena/articles/6f04641801b387)ã€ã§ç´¹ä»‹ã•ã‚Œã¦ã„ã‚‹å½—æ˜Ÿã®å¦‚ãç™»å ´ã—ãŸæœŸå¾…ã®ã‚ªãƒ—ãƒ†ã‚£ãƒã‚¤ã‚¶ã€‚

> - warmupã€learning rate schedulerã€è¨“ç·´çµ‚ç«¯æ™‚åˆ»ã®æŒ‡å®šã€å…¨ã¦ä¸è¦ã§ã™ã€‚
> - å®‰å®šã‹ã¤é«˜é€Ÿã«åæŸã—ã¾ã™ã€‚å¤šãã®å ´åˆã§Adamã‚„AdamWã‚ˆã‚Šå¼·ã„ã§ã™ã€‚

è©³ã—ãã¯è¨˜äº‹ã‚’å‚ç…§ã—ã¦ãã ã•ã„ã€‚

> ç‰¹ã«ã“ã‚Œã§è«–æ–‡ã‚’æ›¸ã„ãŸã‚Šã™ã‚‹ã‚ã‘ã§ã‚‚ãªã„ã®ã§ã€æ–°è¦ã«ç¶²ç¾…çš„ãªæ€§èƒ½å®Ÿé¨“ãªã©ã¯ãŠã“ãªã£ã¦ã„ã¾ã›ã‚“ã€‚ã¤ã¾ã‚Šã€çš†ã•ã‚“ã«ã¨ã£ã¦ã¯ä¾ç„¶ã¨ã—ã¦ã€Œã©ã“ã®é¦¬ã®éª¨ã¨ã‚‚ã‚ã‹ã‚‰ãªã„optimizerã€ã®é¡ã§ã¯ã‚ã‚‹ã‚ã‘ã§ã™ãŒã€ãã‚Œã‚’ã‚ãªãŸã«ã¨ã£ã¦ã®æ–°ã—ã„ã€Œã“ã‚Œä½¿ã£ã¨ãã‚ƒOKã€ã«ã™ã‚‹ã‹ã©ã†ã‹ã¯ã€ã‚ãªãŸã®å¥½å¥‡å¿ƒæ¬¡ç¬¬ã§ã™ã€‚

åˆæœŸè©¦è¡Œã«ã¯é‰„æ¿ã®ã€ŒAdam + CosineAnnealingLRã€ã€å¤§è¦æ¨¡å­¦ç¿’ã«ã¯ã€ŒSGD + StepLRã€ã€å­¦ç¿’ãŒä¸å®‰å®šãªå ´åˆã«ã¯ã€ŒRanger + ExponentialLRã€ã¨ã„ã£ãŸå½¢ãŒä»£è¡¨çš„ã§ã™ã€‚å€‹äººçš„ã«ã¯[schedule_free](https://github.com/facebookresearch/schedule_free)ã«æœŸå¾…ã‚’å¯„ã›ã¦ã„ã¾ã™ã€‚

## [PyTorch Metric Learning](https://kevinmusgrave.github.io/pytorch-metric-learning/)
PyTorch Metric Learningã¯ã€ãƒã‚¤ãƒ‹ãƒ³ã‚°ã‚„ãƒˆãƒªãƒ—ãƒ¬ãƒƒãƒˆãƒ­ã‚¹ã‚’ç”¨ã„ãŸå­¦ç¿’ã‚’ç°¡å˜ã«ã™ã‚‹ãŸã‚ã®ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã§ã™ã€‚

**ç‰¹å¾´**
- Contrastive Lossã‚„Triplet Lossã‚’ã‚µãƒãƒ¼ãƒˆã€‚
- ãƒãƒ¼ãƒ‰ãƒã‚¬ãƒ†ã‚£ãƒ–ãƒã‚¤ãƒ‹ãƒ³ã‚°æ©Ÿèƒ½ã‚ã‚Šã€‚ï¼ˆé ‘å¼·ãªãƒ¢ãƒ‡ãƒ«ãŒã»ã—ã„ãªã‚‰ï¼‰

**åˆ©ç‚¹**
- ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ãŒè±Šå¯Œã§ã‚«ã‚¹ã‚¿ãƒã‚¤ã‚ºãŒå®¹æ˜“ã€‚
- ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆãŒå……å®Ÿã—ã¦ã¦æ‰±ã„ã‚„ã™ã„ã€‚

## å®Ÿè£…ä¾‹

ä»¥ä¸‹ã¯EfficientNetV2ã‚’ãƒãƒƒã‚¯ãƒœãƒ¼ãƒ³ã¨ã—Triplet Lossã‚’ä½¿ç”¨ã—ãŸå­¦ç¿’ã‚³ãƒ¼ãƒ‰ã§ã™ã€‚

```python: siamese_network_training.py
"""siamese_network_training.py.

Summary:
    ã“ã®ã‚¹ã‚¯ãƒªãƒ—ãƒˆã¯ã€PyTorchã‚’ä½¿ç”¨ã—ã¦Siamese Networkã‚’å­¦ç¿’ã™ã‚‹ãŸã‚ã®ã‚³ãƒ¼ãƒ‰ã§ã™ã€‚
    EfficientNetV2ã‚’ãƒãƒƒã‚¯ãƒœãƒ¼ãƒ³ã«æ¡ç”¨ã—ã€æå¤±é–¢æ•°ã¨ã—ã¦Triplet Margin Lossã‚’ä½¿ç”¨ã—ã¦ã„ã¾ã™ã€‚
    è·é›¢è¨ˆé‡ã«ã¯ã‚³ã‚µã‚¤ãƒ³é¡ä¼¼åº¦ã‚’æ¡ç”¨ã—ã¦ã„ã¾ã™ã€‚

    ä¸»ãªç‰¹å¾´:
    - ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’è‡ªç”±ã«è¨­å®šå¯èƒ½ï¼ˆä¾‹: ãƒãƒƒãƒã‚µã‚¤ã‚ºã€åŸ‹ã‚è¾¼ã¿æ¬¡å…ƒã€å­¦ç¿’ç‡ãªã©ï¼‰ã€‚
    - TensorBoardã¨ã®çµ±åˆã«ã‚ˆã‚Šã€å­¦ç¿’ã®é€²æ—ã‚’å¯è¦–åŒ–å¯èƒ½ã€‚
    - ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³çµæœã«åŸºã¥ã„ã¦ã€ãƒ¢ãƒ‡ãƒ«ã‚’ä¿å­˜ã™ã‚‹ä»•çµ„ã¿ã‚’å®Ÿè£…ã€‚
    - PyTorch Metric Learningã®Datasetsæ©Ÿèƒ½ã‚’æ´»ç”¨ã—ãŸç°¡æ½”ãªãƒ‡ãƒ¼ã‚¿ãƒ­ãƒ¼ãƒ€ãƒ¼è¨­å®šã€‚

Example:
    1. `data_dir`ã«ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®ãƒ‘ã‚¹ã‚’æŒ‡å®šã—ã¦ãã ã•ã„ã€‚
    2. ã‚¹ã‚¯ãƒªãƒ—ãƒˆã‚’å®Ÿè¡Œã—ã€TensorBoardã§é€²æ—ã‚’ç¢ºèªã—ã¦ãã ã•ã„ï¼ˆ`tensorboard --logdir=runs`ã‚’ä½¿ç”¨ï¼‰ã€‚

License:
    This script is licensed under the terms provided by yKesamaru, the original author.
"""
import os

import torch
import torch.nn as nn
from pytorch_metric_learning import distances, losses, samplers
from timm import create_model
from torch.utils.data import DataLoader, random_split
from torch.utils.tensorboard import SummaryWriter
from torchvision import transforms
from torchvision.datasets import ImageFolder

# ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®è¨­å®š
embedding_size = 512  # åŸ‹ã‚è¾¼ã¿ãƒ™ã‚¯ãƒˆãƒ«ã®æ¬¡å…ƒæ•°
batch_size = 32  # ãƒãƒƒãƒã‚µã‚¤ã‚º
sampler_m = 4  # ã‚¯ãƒ©ã‚¹ã”ã¨ã«ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ã™ã‚‹ç”»åƒæ•°
data_dir = "path/to/data"  # ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
lr = 1e-4  # å­¦ç¿’ç‡
weight_decay = 1e-5  # æ­£å‰‡åŒ–ã®å¼·ã•
eps = 1e-8  # AdamWã®epsilon
T_max = 50  # å­¦ç¿’ç‡ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ©ã®ã‚µã‚¤ã‚¯ãƒ«é•·
eta_min = 1e-6  # å­¦ç¿’ç‡ã®æœ€å°å€¤
mean_value = [0.485, 0.456, 0.406]  # æ­£è¦åŒ–ã®å¹³å‡å€¤ (EfficientNetV2ç”¨)
std_value = [0.229, 0.224, 0.225]  # æ­£è¦åŒ–ã®æ¨™æº–åå·®
model_save_dir = "saved_models"  # ãƒ¢ãƒ‡ãƒ«ä¿å­˜ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
log_dir = "runs"  # TensorBoardã®ãƒ­ã‚°ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
num_epochs = 100  # å­¦ç¿’ã‚¨ãƒãƒƒã‚¯æ•°
margin = 0.1  # TripletMarginLossã®ãƒãƒ¼ã‚¸ãƒ³å€¤
os.makedirs(model_save_dir, exist_ok=True)
os.makedirs(log_dir, exist_ok=True)

# TensorBoardã®SummaryWriterã‚’åˆæœŸåŒ–
writer = SummaryWriter(log_dir=log_dir)

# ãƒ‡ãƒ¼ã‚¿å¤‰æ›ã®è¨­å®š
train_transform = transforms.Compose([
    transforms.Resize((224, 224)),
    transforms.RandomHorizontalFlip(p=0.5),  # æ°´å¹³æ–¹å‘ã®åè»¢
    transforms.RandomRotation(degrees=15),  # ãƒ©ãƒ³ãƒ€ãƒ ãªå›è»¢
    transforms.RandomResizedCrop(size=(224, 224), scale=(0.8, 1.0), ratio=(0.75, 1.33)),  # ãƒ©ãƒ³ãƒ€ãƒ ãªãƒˆãƒªãƒŸãƒ³ã‚°
    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),
    transforms.ToTensor(),
    transforms.Normalize(mean=mean_value, std=std_value),
])

test_transform = transforms.Compose([
    transforms.Resize((224, 224)),
    transforms.ToTensor(),
    transforms.Normalize(mean=mean_value, std=std_value),
])

# ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®æº–å‚™
train_dataset = ImageFolder(
    root=data_dir,
    transform=train_transform
)

# ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³ã¨ãƒ†ã‚¹ãƒˆã®åˆ†å‰²
val_size = int(0.2 * len(train_dataset))
test_size = len(train_dataset) - val_size
val_dataset, test_dataset = random_split(train_dataset, [val_size, test_size])

# ã‚µãƒ³ãƒ—ãƒ©ãƒ¼ã®è¨­å®šï¼ˆãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ãƒ‡ãƒ¼ã‚¿ã«ã®ã¿é©ç”¨ï¼‰
sampler = samplers.MPerClassSampler([label for _, label in train_dataset.samples], m=sampler_m, batch_size=batch_size)

# ãƒ‡ãƒ¼ã‚¿ãƒ­ãƒ¼ãƒ€ãƒ¼ã®æº–å‚™
train_dataloader = DataLoader(train_dataset, batch_size=batch_size, sampler=sampler, drop_last=True)
val_dataloader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)
test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)


# Siamese Networkã®å®šç¾©
class SiameseNetwork(nn.Module):
    def __init__(self, embedding_dim=embedding_size):
        super(SiameseNetwork, self).__init__()
        # EfficientNetV2ã‚’ãƒãƒƒã‚¯ãƒœãƒ¼ãƒ³ã¨ã—ã¦ä½¿ç”¨ï¼ˆtimmã‹ã‚‰ã‚¤ãƒ³ãƒãƒ¼ãƒˆï¼‰
        self.backbone = create_model('tf_efficientnetv2_b0.in1k', pretrained=True, num_classes=0)
        num_features = self.backbone.num_features  # ãƒãƒƒã‚¯ãƒœãƒ¼ãƒ³ã®ç‰¹å¾´æ¬¡å…ƒæ•°ã‚’å–å¾—
        # åŸ‹ã‚è¾¼ã¿ã‚µã‚¤ã‚ºã‚’æŒ‡å®šã—ã¦å…¨çµåˆå±¤ã‚’è¿½åŠ 
        self.embedder = nn.Linear(num_features, embedding_dim)

    def forward(self, x):
        return self.embedder(self.backbone(x))


# ãƒ¢ãƒ‡ãƒ«ã®åˆæœŸåŒ–
model = SiameseNetwork(embedding_dim=embedding_size)
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
model.to(device)

# ã‚ªãƒ—ãƒ†ã‚£ãƒã‚¤ã‚¶ã®è¨­å®š
optimizer = torch.optim.AdamW(
    model.parameters(),
    lr=lr,
    weight_decay=weight_decay,
    eps=eps
)

# ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ©ã®è¨­å®š
scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(
    optimizer,
    T_max=T_max,
    eta_min=eta_min
)

# æå¤±é–¢æ•°ã®è¨­å®š
loss_fn = losses.TripletMarginLoss(
    margin=margin,
    distance=distances.CosineSimilarity(),
    swap=False
)

# å­¦ç¿’ã‚¹ãƒ†ãƒƒãƒ—ã®ä¾‹
best_loss = float('inf')  # æœ€å°ã®æå¤±ã‚’è¿½è·¡
for epoch in range(1, num_epochs + 1):
    model.train()
    epoch_loss = 0.0
    for batch in train_dataloader:
        optimizer.zero_grad()
        inputs, labels = batch
        inputs = inputs.to(device)
        embeddings = model(inputs)
        loss = loss_fn(embeddings, labels)
        loss.backward()
        optimizer.step()
        epoch_loss += loss.item()
    scheduler.step()

    epoch_loss /= len(train_dataloader)  # ã‚¨ãƒãƒƒã‚¯ã‚ãŸã‚Šã®å¹³å‡æå¤±
    print(f"Epoch {epoch}, Loss: {epoch_loss:.4f}")

    # TensorBoardã¸ã®æ›¸ãè¾¼ã¿
    writer.add_scalar('Loss/train', epoch_loss, epoch)

    # ãƒ¢ãƒ‡ãƒ«ä¿å­˜ã®æ¡ä»¶
    if epoch_loss < best_loss:
        best_loss = epoch_loss
        model_path = os.path.join(model_save_dir, f"model_epoch{epoch}_loss{epoch_loss:.4f}.pth")
        torch.save(model.state_dict(), model_path)
        print(f"Model saved to {model_path}")

writer.close()

```

## æ¤œè¨¼
10ã‚¯ãƒ©ã‚¹åˆ†ã®ãƒ•ã‚©ãƒ«ãƒ€ã‚’ç”¨æ„ã—ã€ãã‚Œãã‚Œã«50æšç¨‹åº¦ã®é¡”ç”»åƒã‚’ã‚»ãƒƒãƒˆã—ã€`siamese_network_training.py`ã‚’10ã‚¨ãƒãƒƒã‚¯å‹•ä½œã•ã›`model_epoch8_loss0.0010.pth`ã‚’å¾—ã¾ã—ãŸã€‚ãƒ•ã‚¡ã‚¤ãƒ«åã«`epoch8`ã¨ã‚ã‚‹ã®ã¯ã€8ã‚¨ãƒãƒƒã‚¯ç›®ä»¥é™ã«ãƒ­ã‚¹ãŒæ¸›å°‘ã—ãªã‹ã£ãŸãŸã‚ã§ã™ã€‚

![](https://raw.githubusercontent.com/yKesamaru/Building_a_face_recognition_model_using_Siamese_Network/refs/heads/master/assets/2024-12-14-10-20-53.png)


### æ¤œè¨¼ã‚³ãƒ¼ãƒ‰
```python: siamese_inference.py
"""siamese_inference.py.

Summary:
    ã“ã®ã‚¹ã‚¯ãƒªãƒ—ãƒˆã¯ã€å­¦ç¿’æ¸ˆã¿ã®Siamese Networkãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ç”¨ã—ã¦2ã¤ã®ç”»åƒé–“ã®é¡ä¼¼åº¦ã‚’è¨ˆç®—ã—ã¾ã™ã€‚

    ä¸»ãªæ©Ÿèƒ½:
    - å­¦ç¿’æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ã®ãƒ­ãƒ¼ãƒ‰
    - ç”»åƒã®å‰å‡¦ç†
    - ç‰¹å¾´ãƒ™ã‚¯ãƒˆãƒ«ã®æŠ½å‡º
    - ã‚³ã‚µã‚¤ãƒ³é¡ä¼¼åº¦ã®è¨ˆç®—

Example:
    python siamese_inference.py --model_path path/to/saved_model.pth --img1 path/to/image1.png --img2 path/to/image2.png

License:
    This script is licensed under the terms provided by yKesamaru, the original author.
"""
import torch
import torch.nn as nn
import torch.nn.functional as F
from timm import create_model
from torchvision import transforms
from PIL import Image
import argparse


# Siamese Networkã®å®šç¾©
class SiameseNetwork(nn.Module):
    def __init__(self, embedding_dim=512):
        super(SiameseNetwork, self).__init__()
        self.backbone = create_model('tf_efficientnetv2_b0.in1k', pretrained=False, num_classes=0)
        num_features = self.backbone.num_features
        self.embedder = nn.Linear(num_features, embedding_dim)

    def forward(self, x):
        return self.embedder(self.backbone(x))


def load_model(model_path, embedding_dim=512):
    """å­¦ç¿’æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ã‚’ãƒ­ãƒ¼ãƒ‰ã—ã¾ã™ã€‚

    Args:
        model_path (str): ãƒ¢ãƒ‡ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹
        embedding_dim (int): åŸ‹ã‚è¾¼ã¿ãƒ™ã‚¯ãƒˆãƒ«ã®æ¬¡å…ƒæ•°

    Returns:
        SiameseNetwork: ãƒ­ãƒ¼ãƒ‰ã•ã‚ŒãŸãƒ¢ãƒ‡ãƒ«
    """
    model = SiameseNetwork(embedding_dim)
    model.load_state_dict(torch.load(model_path, map_location="cpu"))
    model.eval()
    return model


def preprocess_image(image_path):
    """ç”»åƒã‚’å‰å‡¦ç†ã—ã¾ã™ã€‚

    Args:
        image_path (str): ç”»åƒãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹

    Returns:
        torch.Tensor: å‰å‡¦ç†æ¸ˆã¿ã®ç”»åƒãƒ†ãƒ³ã‚½ãƒ«
    """
    transform = transforms.Compose([
        transforms.Resize((224, 224)),
        transforms.ToTensor(),
        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),
    ])
    img = Image.open(image_path).convert("RGB")
    return transform(img).unsqueeze(0)  # ãƒãƒƒãƒæ¬¡å…ƒã‚’è¿½åŠ 


def compute_similarity(model, img1_path, img2_path):
    """2ã¤ã®ç”»åƒé–“ã®é¡ä¼¼åº¦ã‚’è¨ˆç®—ã—ã¾ã™ã€‚

    Args:
        model (SiameseNetwork): Siamese Networkãƒ¢ãƒ‡ãƒ«
        img1_path (str): 1æšç›®ã®ç”»åƒã®ãƒ‘ã‚¹
        img2_path (str): 2æšç›®ã®ç”»åƒã®ãƒ‘ã‚¹

    Returns:
        float: ã‚³ã‚µã‚¤ãƒ³é¡ä¼¼åº¦
    """
    img1_tensor = preprocess_image(img1_path)
    img2_tensor = preprocess_image(img2_path)
    with torch.no_grad():
        embedding1 = model(img1_tensor)
        embedding2 = model(img2_tensor)
    similarity = F.cosine_similarity(embedding1, embedding2).item()
    return similarity


def main():
    # å¼•æ•°ã‚’è§£æ
    parser = argparse.ArgumentParser(description="Siamese Networkã‚’ç”¨ã„ãŸç”»åƒé–“é¡ä¼¼åº¦è¨ˆç®—")
    parser.add_argument("--model_path", type=str, required=True, help="å­¦ç¿’æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ã®ãƒ‘ã‚¹")
    parser.add_argument("--img1", type=str, required=True, help="1æšç›®ã®ç”»åƒã®ãƒ‘ã‚¹")
    parser.add_argument("--img2", type=str, required=True, help="2æšç›®ã®ç”»åƒã®ãƒ‘ã‚¹")
    args = parser.parse_args()

    # ãƒ¢ãƒ‡ãƒ«ã®ãƒ­ãƒ¼ãƒ‰
    print("ãƒ¢ãƒ‡ãƒ«ã‚’ãƒ­ãƒ¼ãƒ‰ä¸­...")
    model = load_model(args.model_path)

    # é¡ä¼¼åº¦ã®è¨ˆç®—
    print("é¡ä¼¼åº¦ã‚’è¨ˆç®—ä¸­...")
    similarity = compute_similarity(model, args.img1, args.img2)
    print(f"ç”»åƒé–“ã®é¡ä¼¼åº¦: {similarity:.4f}")


if __name__ == "__main__":
    main()

```

### æ¤œè¨¼çµæœ
![](https://raw.githubusercontent.com/yKesamaru/Building_a_face_recognition_model_using_Siamese_Network/refs/heads/master/assets/2024-12-14-10-33-43.png)

ä¸Šè¨˜ã®ç”»åƒã§å­¦ç¿’ã—ãŸå¾Œã€ä»¥ä¸‹ã®**å­¦ç¿’ã«ä½¿ã£ã¦ã„ãªã„ç”»åƒ**ã§é¡ä¼¼åº¦ã‚’è¨ˆç®—ã—ã¾ã—ãŸã€‚

![](https://raw.githubusercontent.com/yKesamaru/Building_a_face_recognition_model_using_Siamese_Network/refs/heads/master/assets/2024-12-14-10-34-46.png)

```bash
(pytorch-metric-learning) user@user:~/bin/pytorch-metric-learning$ python siamese_inference.py --model_path /home/user/bin/pytorch-metric-learning/saved_models/model_epoch8_loss0.0010.pth --img1 /home/user/bin/pytorch-metric-learning/otameshi_data/ã¤ã˜ã‹ã‚Šã‚“/ã¤ã˜ã‹ã‚Šã‚“_wplw.jpeg..png.png.png_0_align_resize_refined.png --img2  /home/user/bin/pytorch-metric-learning/otameshi_data/ã¤ã˜ã‹ã‚Šã‚“/ã¤ã˜ã‹ã‚Šã‚“.png
ãƒ¢ãƒ‡ãƒ«ã‚’ãƒ­ãƒ¼ãƒ‰ä¸­...
é¡ä¼¼åº¦ã‚’è¨ˆç®—ä¸­...
ç”»åƒé–“ã®é¡ä¼¼åº¦: 0.9428
```

**é¡ä¼¼åº¦ã¯0.9428**ã¨ãªã‚Šã€æœ¬äººã§ã‚ã‚‹ã“ã¨ãŒå¼·ãç¤ºå”†ã•ã‚Œã¾ã—ãŸã€‚

ãã‚Œã§ã¯æ—¢å­˜ã®ã‚¯ãƒ©ã‚¹ã ã‘ã§ã¯ãªãã€æœªçŸ¥ã®ã‚¯ãƒ©ã‚¹ã¸ã®æ±ç”¨æ€§ã¯ã©ã†ã§ã—ã‚‡ã†ã‹ï¼Ÿ

æ¤œè¨¼ã®ãŸã‚ã«ã€**å­¦ç¿’ã§ã¯ç”¨ã„ãªã‹ã£ãŸ20ã‚¯ãƒ©ã‚¹åˆ†ï¼ˆæœªçŸ¥ã®20äººï¼‰**ã®ãƒ•ã‚©ãƒ«ãƒ€ã‚’ç”¨æ„ã—ã€ãã‚Œãã‚Œã«50æšç¨‹åº¦ã®é¡”ç”»åƒã‚’ã‚»ãƒƒãƒˆã—ã¾ã—ãŸã€‚

`aoc_plot_siamese_1-N.py`ã¨ã„ã†AUCã‚¹ã‚³ã‚¢ã¨ROCæ›²ç·šã‚’ãƒ—ãƒ­ãƒƒãƒˆã™ã‚‹ã‚³ãƒ¼ãƒ‰ã‚’æ›¸ã„ã¦æ¤œè¨¼ã—ã¾ã™ã€‚

ã“ã®ã‚³ãƒ¼ãƒ‰ã¯ãã®ãƒ•ã‚¡ã‚¤ãƒ«åãŒç¤ºã™ã¨ãŠã‚Šã€1å¯¾å¤šãƒ¢ãƒ¼ãƒ‰ç”¨ã®ç²¾åº¦æ¤œè¨¼ç”¨ã‚³ãƒ¼ãƒ‰ã§ã™ã€‚ã¾ãšã¯ã“ã¡ã‚‰ã§æ±åŒ–æ€§èƒ½ã‚’ã¿ã¦ã¿ã¾ã™ã€‚

```python: aoc_plot_siamese.py
"""aoc_plot_siamese_1-N.py.

Summary:
    ã“ã®ã‚¹ã‚¯ãƒªãƒ—ãƒˆã¯ã€å­¦ç¿’æ¸ˆã¿ã®Siamese Networkãƒ¢ãƒ‡ãƒ«ã‚’ç”¨ã„ã¦
    ROCæ›²ç·šï¼ˆAOCæ›²ç·šï¼‰ã‚’ãƒ—ãƒ­ãƒƒãƒˆã™ã‚‹ãŸã‚ã®ã‚³ãƒ¼ãƒ‰ã§ã™ã€‚
    ã“ã®ã‚¹ã‚¯ãƒªãƒ—ãƒˆã¯1å¯¾1ãƒ¢ãƒ¼ãƒ‰ã§ã¯ãªãã€1å¯¾Nãƒ¢ãƒ¼ãƒ‰ã®ç²¾åº¦ã‚’æ¤œè¨¼ã—ã¾ã™ã€‚
    1å¯¾1ãƒ¢ãƒ¼ãƒ‰ã§å­¦ç¿’ã•ã‚ŒãŸãƒ¢ãƒ‡ãƒ«ã‚’è©•ä¾¡ã—ãŸå ´åˆã€ä¸€èˆ¬çš„ã«ç²¾åº¦ã¯ä½ãå‡ºåŠ›ã•ã‚Œã¾ã™ã€‚

    ä¸»ãªæ©Ÿèƒ½:
    - æ¤œè¨¼ç”¨ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‹ã‚‰åŸ‹ã‚è¾¼ã¿ãƒ™ã‚¯ãƒˆãƒ«ã‚’ç”Ÿæˆã€‚
    - åŸ‹ã‚è¾¼ã¿ãƒ™ã‚¯ãƒˆãƒ«é–“ã®ã‚³ã‚µã‚¤ãƒ³é¡ä¼¼åº¦ã‚’è¨ˆç®—ã€‚
    - ROCæ›²ç·šã‚’æç”»ã—ã€AUCã‚¹ã‚³ã‚¢ã‚’ç®—å‡ºã€‚
    - ãƒ—ãƒ­ãƒƒãƒˆç”»åƒã‚’ã‚«ãƒ¬ãƒ³ãƒˆãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã«ä¿å­˜ã€‚

License:
    This script is licensed under the terms provided by yKesamaru, the original author.
"""

import matplotlib.pyplot as plt
import torch
import torch.nn as nn
from sklearn.metrics import roc_auc_score, roc_curve
from timm import create_model
from torchvision import datasets, transforms
from tqdm import tqdm


# SiameseNetworkã‚¯ãƒ©ã‚¹ã®å®šç¾©
class SiameseNetwork(nn.Module):
    """
    Siamese Networkã®ã‚¯ãƒ©ã‚¹å®šç¾©ã€‚
    EfficientNetV2ã‚’ãƒãƒƒã‚¯ãƒœãƒ¼ãƒ³ã¨ã—ã¦ä½¿ç”¨ã€‚

    Args:
        embedding_dim (int): åŸ‹ã‚è¾¼ã¿ãƒ™ã‚¯ãƒˆãƒ«ã®æ¬¡å…ƒæ•°ã€‚
    """
    def __init__(self, embedding_dim=512):
        super(SiameseNetwork, self).__init__()
        self.backbone = create_model('tf_efficientnetv2_b0.in1k', pretrained=True, num_classes=0)
        num_features = self.backbone.num_features
        self.embedder = nn.Linear(num_features, embedding_dim)

    def forward(self, x):
        return self.embedder(self.backbone(x))


# å­¦ç¿’æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ã®èª­ã¿è¾¼ã¿
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
model_path = "/home/user/bin/pytorch-metric-learning/saved_models/model_epoch8_loss0.0010.pth"
model = SiameseNetwork(embedding_dim=512)  # å­¦ç¿’æ™‚ã¨åŒã˜ãƒ¢ãƒ‡ãƒ«æ§‹é€ ã‚’å†ç¾
model.load_state_dict(torch.load(model_path, map_location=device))
model.eval().to(device)

# æ¤œè¨¼ç”¨ãƒ‡ãƒ¼ã‚¿ã®ãƒ‘ã‚¹
test_data_dir = "/home/user/bin/pytorch-metric-learning/otameshi_kensho/"

# æ¤œè¨¼ç”¨ãƒ‡ãƒ¼ã‚¿ã®å¤‰æ›
test_transform = transforms.Compose([
    transforms.Resize((224, 224)),
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),
])

# ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®ä½œæˆ
test_dataset = datasets.ImageFolder(root=test_data_dir, transform=test_transform)
test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=1, shuffle=False)


def calculate_similarity(embedding1, embedding2):
    """
    åŸ‹ã‚è¾¼ã¿ãƒ™ã‚¯ãƒˆãƒ«é–“ã®ã‚³ã‚µã‚¤ãƒ³é¡ä¼¼åº¦ã‚’è¨ˆç®—ã™ã‚‹ã€‚

    Args:
        embedding1 (torch.Tensor): åŸ‹ã‚è¾¼ã¿ãƒ™ã‚¯ãƒˆãƒ«1ã€‚
        embedding2 (torch.Tensor): åŸ‹ã‚è¾¼ã¿ãƒ™ã‚¯ãƒˆãƒ«2ã€‚

    Returns:
        float: ã‚³ã‚µã‚¤ãƒ³é¡ä¼¼åº¦ã€‚
    """
    return torch.nn.functional.cosine_similarity(embedding1, embedding2).item()


def compute_embeddings(loader, model):
    """
    ãƒ‡ãƒ¼ã‚¿ãƒ­ãƒ¼ãƒ€ãƒ¼ã‚’ç”¨ã„ã¦åŸ‹ã‚è¾¼ã¿ãƒ™ã‚¯ãƒˆãƒ«ã‚’è¨ˆç®—ã€‚

    Args:
        loader (torch.utils.data.DataLoader): ãƒ‡ãƒ¼ã‚¿ãƒ­ãƒ¼ãƒ€ãƒ¼ã€‚
        model (torch.nn.Module): å­¦ç¿’æ¸ˆã¿Siameseãƒ¢ãƒ‡ãƒ«ã€‚

    Returns:
        dict: ã‚¯ãƒ©ã‚¹ã”ã¨ã®åŸ‹ã‚è¾¼ã¿ãƒ™ã‚¯ãƒˆãƒ«ã®è¾æ›¸ã€‚
    """
    embeddings = {}
    for img, label in tqdm(loader, desc="Computing Embeddings"):
        with torch.no_grad():
            img = img.to(device)
            embedding = model(img)
            embeddings[label.item()] = embeddings.get(label.item(), []) + [embedding]
    return embeddings


def calculate_similarities_and_labels(embeddings):
    """
    ã‚¯ãƒ©ã‚¹ã”ã¨ã®åŸ‹ã‚è¾¼ã¿ãƒ™ã‚¯ãƒˆãƒ«ã‚’ç”¨ã„ã¦é¡ä¼¼åº¦ã¨ãƒ©ãƒ™ãƒ«ã‚’è¨ˆç®—ã€‚

    Args:
        embeddings (dict): ã‚¯ãƒ©ã‚¹ã”ã¨ã®åŸ‹ã‚è¾¼ã¿ãƒ™ã‚¯ãƒˆãƒ«ã®è¾æ›¸ã€‚

    Returns:
        tuple: é¡ä¼¼åº¦ãƒªã‚¹ãƒˆã€ãƒ©ãƒ™ãƒ«ãƒªã‚¹ãƒˆã€‚
    """
    similarities = []
    labels = []
    class_keys = list(embeddings.keys())

    for i, class_label_1 in enumerate(class_keys):
        for embedding1 in embeddings[class_label_1]:
            # åŒã˜ã‚¯ãƒ©ã‚¹ã¨ã®æ¯”è¼ƒï¼ˆãƒ©ãƒ™ãƒ«=1ï¼‰
            for embedding2 in embeddings[class_label_1]:
                if not torch.equal(embedding1, embedding2):  # åŒã˜ç”»åƒã¯ã‚¹ã‚­ãƒƒãƒ—
                    sim = calculate_similarity(embedding1, embedding2)
                    similarities.append(sim)
                    labels.append(1)  # åŒã˜ã‚¯ãƒ©ã‚¹ã¯ãƒ©ãƒ™ãƒ«1

            # ç•°ãªã‚‹ã‚¯ãƒ©ã‚¹ã¨ã®æ¯”è¼ƒï¼ˆãƒ©ãƒ™ãƒ«=0ï¼‰
            for j, class_label_2 in enumerate(class_keys):
                if i != j:  # ç•°ãªã‚‹ã‚¯ãƒ©ã‚¹ã®ã¿
                    for embedding2 in embeddings[class_label_2]:
                        sim = calculate_similarity(embedding1, embedding2)
                        similarities.append(sim)
                        labels.append(0)  # ç•°ãªã‚‹ã‚¯ãƒ©ã‚¹ã¯ãƒ©ãƒ™ãƒ«0

    return similarities, labels


def plot_roc_curve(similarities, labels, output_path="roc_curve.png"):
    """
    ROCæ›²ç·šã‚’ãƒ—ãƒ­ãƒƒãƒˆã—ã€ç”»åƒã¨ã—ã¦ä¿å­˜ã™ã‚‹ã€‚

    Args:
        similarities (list): é¡ä¼¼åº¦ãƒªã‚¹ãƒˆã€‚
        labels (list): ãƒ©ãƒ™ãƒ«ãƒªã‚¹ãƒˆã€‚
        output_path (str): ãƒ—ãƒ­ãƒƒãƒˆç”»åƒã®ä¿å­˜ãƒ‘ã‚¹ã€‚
    """
    fpr, tpr, thresholds = roc_curve(labels, similarities)
    auc = roc_auc_score(labels, similarities)

    plt.figure(figsize=(8, 6))
    plt.plot(fpr, tpr, label=f"AUC = {auc:.4f}")
    plt.xlabel("False Positive Rate")
    plt.ylabel("True Positive Rate")
    plt.title("ROC Curve")
    plt.legend()
    plt.grid()
    plt.savefig(output_path)  # ç”»åƒã‚’ä¿å­˜
    plt.show()


if __name__ == "__main__":
    # åŸ‹ã‚è¾¼ã¿ãƒ™ã‚¯ãƒˆãƒ«ã®è¨ˆç®—
    embeddings = compute_embeddings(test_loader, model)

    # é¡ä¼¼åº¦ã¨ãƒ©ãƒ™ãƒ«ã®è¨ˆç®—
    similarities, labels = calculate_similarities_and_labels(embeddings)

    # ROCæ›²ç·šã®ãƒ—ãƒ­ãƒƒãƒˆã¨ä¿å­˜
    plot_roc_curve(similarities, labels, output_path="roc_curve.png")

```

![](https://raw.githubusercontent.com/yKesamaru/Building_a_face_recognition_model_using_Siamese_Network/refs/heads/master/assets/roc_curve.png)

ã•ã™ãŒã«10ã‚¯ãƒ©ã‚¹ã—ã‹å­¦ç¿’ã—ã¦ã„ãªã„å­¦ç¿’æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ã§ã¯ã€æœªçŸ¥ã®20ã‚¯ãƒ©ã‚¹ã«å¯¾ã—ã¦ã¾ã¨ã‚‚ãªç²¾åº¦ã¯å‡ºã›ãªã„ã§ã™ã­ã€‚

ã¨ã¯ã„ãˆã€ä»Šã®ã¯1å¯¾å¤šãƒ¢ãƒ¼ãƒ‰ç”¨ã®ã‚³ãƒ¼ãƒ‰ã§ã—ãŸã€‚æ¬¡ã¯1å¯¾1ãƒ¢ãƒ¼ãƒ‰ç”¨ã®ROCæ›²ç·šä½œæˆã‚³ãƒ¼ãƒ‰ï¼ˆ`aoc_plot_siamese_1-N.py`ï¼‰ã‚’ç”¨æ„ã—ã¦å®Ÿè¡Œã—ã¦ã¿ã¾ã™ã€‚

```python
"""aoc_plot_siamese_1-N.py.

Summary:
    ã“ã®ã‚¹ã‚¯ãƒªãƒ—ãƒˆã¯ã€å­¦ç¿’æ¸ˆã¿ã®Siamese Networkãƒ¢ãƒ‡ãƒ«ã‚’ç”¨ã„ã¦
    ROCæ›²ç·šï¼ˆAOCæ›²ç·šï¼‰ã‚’ãƒ—ãƒ­ãƒƒãƒˆã™ã‚‹ãŸã‚ã®ã‚³ãƒ¼ãƒ‰ã§ã™ã€‚
    ã“ã®ã‚¹ã‚¯ãƒªãƒ—ãƒˆã¯1å¯¾1ãƒ¢ãƒ¼ãƒ‰ã§ã¯ãªãã€1å¯¾Nãƒ¢ãƒ¼ãƒ‰ã®ç²¾åº¦ã‚’æ¤œè¨¼ã—ã¾ã™ã€‚
    1å¯¾1ãƒ¢ãƒ¼ãƒ‰ã§å­¦ç¿’ã•ã‚ŒãŸãƒ¢ãƒ‡ãƒ«ã‚’è©•ä¾¡ã—ãŸå ´åˆã€ä¸€èˆ¬çš„ã«ç²¾åº¦ã¯ä½ãå‡ºåŠ›ã•ã‚Œã¾ã™ã€‚

    ä¸»ãªæ©Ÿèƒ½:
    - æ¤œè¨¼ç”¨ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‹ã‚‰åŸ‹ã‚è¾¼ã¿ãƒ™ã‚¯ãƒˆãƒ«ã‚’ç”Ÿæˆã€‚
    - åŸ‹ã‚è¾¼ã¿ãƒ™ã‚¯ãƒˆãƒ«é–“ã®ã‚³ã‚µã‚¤ãƒ³é¡ä¼¼åº¦ã‚’è¨ˆç®—ã€‚
    - ROCæ›²ç·šã‚’æç”»ã—ã€AUCã‚¹ã‚³ã‚¢ã‚’ç®—å‡ºã€‚
    - ãƒ—ãƒ­ãƒƒãƒˆç”»åƒã‚’ã‚«ãƒ¬ãƒ³ãƒˆãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã«ä¿å­˜ã€‚

License:
    This script is licensed under the terms provided by yKesamaru, the original author.
"""

import matplotlib.pyplot as plt
import torch
import torch.nn as nn
from sklearn.metrics import roc_auc_score, roc_curve
from timm import create_model
from torchvision import datasets, transforms
from tqdm import tqdm


# SiameseNetworkã‚¯ãƒ©ã‚¹ã®å®šç¾©
class SiameseNetwork(nn.Module):
    """
    Siamese Networkã®ã‚¯ãƒ©ã‚¹å®šç¾©ã€‚
    EfficientNetV2ã‚’ãƒãƒƒã‚¯ãƒœãƒ¼ãƒ³ã¨ã—ã¦ä½¿ç”¨ã€‚

    Args:
        embedding_dim (int): åŸ‹ã‚è¾¼ã¿ãƒ™ã‚¯ãƒˆãƒ«ã®æ¬¡å…ƒæ•°ã€‚
    """
    def __init__(self, embedding_dim=512):
        super(SiameseNetwork, self).__init__()
        self.backbone = create_model('tf_efficientnetv2_b0.in1k', pretrained=True, num_classes=0)
        num_features = self.backbone.num_features
        self.embedder = nn.Linear(num_features, embedding_dim)

    def forward(self, x):
        return self.embedder(self.backbone(x))


# å­¦ç¿’æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ã®èª­ã¿è¾¼ã¿
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
model_path = "/home/user/bin/pytorch-metric-learning/saved_models/model_epoch8_loss0.0010.pth"
model = SiameseNetwork(embedding_dim=512)  # å­¦ç¿’æ™‚ã¨åŒã˜ãƒ¢ãƒ‡ãƒ«æ§‹é€ ã‚’å†ç¾
model.load_state_dict(torch.load(model_path, map_location=device))
model.eval().to(device)

# æ¤œè¨¼ç”¨ãƒ‡ãƒ¼ã‚¿ã®ãƒ‘ã‚¹
test_data_dir = "/home/user/bin/pytorch-metric-learning/otameshi_kensho/"

# æ¤œè¨¼ç”¨ãƒ‡ãƒ¼ã‚¿ã®å¤‰æ›
test_transform = transforms.Compose([
    transforms.Resize((224, 224)),
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),
])

# ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®ä½œæˆ
test_dataset = datasets.ImageFolder(root=test_data_dir, transform=test_transform)
test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=1, shuffle=False)


def calculate_similarity(embedding1, embedding2):
    """
    åŸ‹ã‚è¾¼ã¿ãƒ™ã‚¯ãƒˆãƒ«é–“ã®ã‚³ã‚µã‚¤ãƒ³é¡ä¼¼åº¦ã‚’è¨ˆç®—ã™ã‚‹ã€‚

    Args:
        embedding1 (torch.Tensor): åŸ‹ã‚è¾¼ã¿ãƒ™ã‚¯ãƒˆãƒ«1ã€‚
        embedding2 (torch.Tensor): åŸ‹ã‚è¾¼ã¿ãƒ™ã‚¯ãƒˆãƒ«2ã€‚

    Returns:
        float: ã‚³ã‚µã‚¤ãƒ³é¡ä¼¼åº¦ã€‚
    """
    return torch.nn.functional.cosine_similarity(embedding1, embedding2).item()


def compute_embeddings(loader, model):
    """
    ãƒ‡ãƒ¼ã‚¿ãƒ­ãƒ¼ãƒ€ãƒ¼ã‚’ç”¨ã„ã¦åŸ‹ã‚è¾¼ã¿ãƒ™ã‚¯ãƒˆãƒ«ã‚’è¨ˆç®—ã€‚

    Args:
        loader (torch.utils.data.DataLoader): ãƒ‡ãƒ¼ã‚¿ãƒ­ãƒ¼ãƒ€ãƒ¼ã€‚
        model (torch.nn.Module): å­¦ç¿’æ¸ˆã¿Siameseãƒ¢ãƒ‡ãƒ«ã€‚

    Returns:
        dict: ã‚¯ãƒ©ã‚¹ã”ã¨ã®åŸ‹ã‚è¾¼ã¿ãƒ™ã‚¯ãƒˆãƒ«ã®è¾æ›¸ã€‚
    """
    embeddings = {}
    for img, label in tqdm(loader, desc="Computing Embeddings"):
        with torch.no_grad():
            img = img.to(device)
            embedding = model(img)
            embeddings[label.item()] = embeddings.get(label.item(), []) + [embedding]
    return embeddings


def calculate_similarities_and_labels(embeddings):
    """
    ã‚¯ãƒ©ã‚¹ã”ã¨ã®åŸ‹ã‚è¾¼ã¿ãƒ™ã‚¯ãƒˆãƒ«ã‚’ç”¨ã„ã¦é¡ä¼¼åº¦ã¨ãƒ©ãƒ™ãƒ«ã‚’è¨ˆç®—ã€‚

    Args:
        embeddings (dict): ã‚¯ãƒ©ã‚¹ã”ã¨ã®åŸ‹ã‚è¾¼ã¿ãƒ™ã‚¯ãƒˆãƒ«ã®è¾æ›¸ã€‚

    Returns:
        tuple: é¡ä¼¼åº¦ãƒªã‚¹ãƒˆã€ãƒ©ãƒ™ãƒ«ãƒªã‚¹ãƒˆã€‚
    """
    similarities = []
    labels = []
    class_keys = list(embeddings.keys())

    for i, class_label_1 in enumerate(class_keys):
        for embedding1 in embeddings[class_label_1]:
            # åŒã˜ã‚¯ãƒ©ã‚¹ã¨ã®æ¯”è¼ƒï¼ˆãƒ©ãƒ™ãƒ«=1ï¼‰
            for embedding2 in embeddings[class_label_1]:
                if not torch.equal(embedding1, embedding2):  # åŒã˜ç”»åƒã¯ã‚¹ã‚­ãƒƒãƒ—
                    sim = calculate_similarity(embedding1, embedding2)
                    similarities.append(sim)
                    labels.append(1)  # åŒã˜ã‚¯ãƒ©ã‚¹ã¯ãƒ©ãƒ™ãƒ«1

            # ç•°ãªã‚‹ã‚¯ãƒ©ã‚¹ã¨ã®æ¯”è¼ƒï¼ˆãƒ©ãƒ™ãƒ«=0ï¼‰
            for j, class_label_2 in enumerate(class_keys):
                if i != j:  # ç•°ãªã‚‹ã‚¯ãƒ©ã‚¹ã®ã¿
                    for embedding2 in embeddings[class_label_2]:
                        sim = calculate_similarity(embedding1, embedding2)
                        similarities.append(sim)
                        labels.append(0)  # ç•°ãªã‚‹ã‚¯ãƒ©ã‚¹ã¯ãƒ©ãƒ™ãƒ«0

    return similarities, labels


def plot_roc_curve(similarities, labels, output_path="roc_curve.png"):
    """
    ROCæ›²ç·šã‚’ãƒ—ãƒ­ãƒƒãƒˆã—ã€ç”»åƒã¨ã—ã¦ä¿å­˜ã™ã‚‹ã€‚

    Args:
        similarities (list): é¡ä¼¼åº¦ãƒªã‚¹ãƒˆã€‚
        labels (list): ãƒ©ãƒ™ãƒ«ãƒªã‚¹ãƒˆã€‚
        output_path (str): ãƒ—ãƒ­ãƒƒãƒˆç”»åƒã®ä¿å­˜ãƒ‘ã‚¹ã€‚
    """
    fpr, tpr, thresholds = roc_curve(labels, similarities)
    auc = roc_auc_score(labels, similarities)

    plt.figure(figsize=(8, 6))
    plt.plot(fpr, tpr, label=f"AUC = {auc:.4f}")
    plt.xlabel("False Positive Rate")
    plt.ylabel("True Positive Rate")
    plt.title("ROC Curve")
    plt.legend()
    plt.grid()
    plt.savefig(output_path)  # ç”»åƒã‚’ä¿å­˜
    plt.show()


if __name__ == "__main__":
    # åŸ‹ã‚è¾¼ã¿ãƒ™ã‚¯ãƒˆãƒ«ã®è¨ˆç®—
    embeddings = compute_embeddings(test_loader, model)

    # é¡ä¼¼åº¦ã¨ãƒ©ãƒ™ãƒ«ã®è¨ˆç®—
    similarities, labels = calculate_similarities_and_labels(embeddings)

    # ROCæ›²ç·šã®ãƒ—ãƒ­ãƒƒãƒˆã¨ä¿å­˜
    plot_roc_curve(similarities, labels, output_path="roc_curve.png")

```

![](https://raw.githubusercontent.com/yKesamaru/Building_a_face_recognition_model_using_Siamese_Network/refs/heads/master/assets/roc_curve_1to1.png)

orz...
ã•ã£ãã‚ˆã‚Šæ‚ªã„çµæœãŒå‡ºã¾ã—ãŸã€‚

ã¾ãã€10ã‚¯ãƒ©ã‚¹ï¼ˆå„ã‚¯ãƒ©ã‚¹50æšç¨‹åº¦ã®é¡”ç”»åƒãƒ•ã‚¡ã‚¤ãƒ«ï¼‰ã§10ã‚¨ãƒãƒƒã‚¯ã—ã‹å­¦ç¿’ã—ã¦ã„ãªã„ã‚ã‘ã§ã™ã‹ã‚‰ã“ã‚“ãªã‚‚ã®ã§ã™ã€‚ã¾ã¨ã‚‚ãªçµæœã‚’å‡ºã—ãŸã‘ã‚Œã°1000ã‚¯ãƒ©ã‚¹ä»¥ä¸Šï¼ˆå„ã‚¯ãƒ©ã‚¹100æšä»¥ä¸Šã®é¡”ç”»åƒãƒ•ã‚¡ã‚¤ãƒ«ï¼‰ãŒã©ã†ã—ãŸã£ã¦å¿…è¦ã§ã™ã€‚

ã¨ã¯ã„ãˆã€è¨˜äº‹ä½œæˆç”¨ã®å­¦ç¿’ãªã‚‰ã“ã‚Œãã‚‰ã„ã§ã„ã£ã‹â€¦ã¨è€ƒãˆã¦ã„ãŸã®ã§ã™ãŒã€ã•ã™ãŒã«æ‚”ã—ããªã‚Šã¾ã—ãŸã€‚

ç¾åœ¨ã€2000ã‚¯ãƒ©ã‚¹ã«å¯¾ã—ã¦å­¦ç¿’ã‚’ã•ã›ã¦ã„ã‚‹ã¨ã“ã‚ã§ã™ã€‚

â€¦ãŒã€è¨˜äº‹ä½œæˆæ™‚ç‚¹ã§1ã‚¨ãƒãƒƒã‚¯ã—ã‹çµ‚ã‚ã£ã¦ã¾ã›ã‚“ã§ã—ãŸã€‚å…ˆã¯é•·ãã†ã§ã™ã€‚


## ã•ã„ã”ã«
æœ¬è¨˜äº‹ã§ã¯Siamese Networkã‚’ç”¨ã„ãŸ1å¯¾1ãƒ¢ãƒ¼ãƒ‰ã®å­¦ç¿’ãƒ¢ãƒ‡ãƒ«ã‚’ä½œæˆã™ã‚‹ãŸã‚ã®ã‚³ãƒ¼ãƒ‰ã‚’ä½œæˆãƒ»å®Ÿè¡Œãƒ»æ¤œè¨¼ã—ã¾ã—ãŸã€‚

1å¯¾1ãƒ¢ãƒ¼ãƒ‰ãŒã©ã†ã„ã†ã‚‚ã®ã‹ã€èªè¨¼ç•Œéšˆã®è§£èª¬ï¼ˆèªè¨¼ã®ã‚¹ã‚³ãƒ¼ãƒ—ãªã©ï¼‰ã‚‚ç°¡å˜ã§ã™ãŒåŠ ãˆã¾ã—ãŸã€‚

ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã¨GPUãŒã‚ã‚Œã°ã€ã‚ãªãŸå°‚ç”¨ã®å­¦ç¿’ãƒ¢ãƒ‡ãƒ«ãŒä½œã‚Œã¡ã‚ƒã„ã¾ã™ã­ğŸ˜€

ä»¥ä¸Šã§ã™ã€‚ã‚ã‚ŠãŒã¨ã†ã”ã–ã„ã¾ã—ãŸã€‚

## ãŠã¾ã‘
1å¯¾å¤šãƒ¢ãƒ¼ãƒ‰ã®å­¦ç¿’ãƒ¢ãƒ‡ãƒ«ã¯`JAPANESE FACE V1`ã¨ã—ã¦ä»¥ä¸‹ã§é…å¸ƒã—ã¦ã¾ã™ã€‚

https://github.com/yKesamaru/FACE01_trained_models

ä½¿ã£ã¦ã¿ã¦ã­â­ï¸

![](https://raw.githubusercontent.com/yKesamaru/Building_a_face_recognition_model_using_Siamese_Network/refs/heads/master/assets/2024-12-14-22-36-04.png)

## æ–‡çŒ®ãƒ»å‚è€ƒã‚µã‚¤ãƒˆ
- [Siamese Networkã¨Contrastive Lossã‚’å¾¹åº•è§£èª¬ - ã¯ã‚„ã¶ã•ã®æŠ€è¡“ãƒãƒ¼ãƒˆ](https://cpp-learning.com/siamese-network/)
- [Siamese Networkã®ææ¡ˆè«–æ–‡ï¼ˆNIPS1993ï¼‰](https://papers.nips.cc/paper/1993/file/288cc0ff022877bd3df94bc9360b9c5d-Paper.pdf)
- [J-GLOBALã§ã®æ‰‹æ›¸ãæ–‡å­—èªè¨¼ã«é–¢ã™ã‚‹æƒ…å ±](https://jglobal.jst.go.jp/detail?JGLOBAL_ID=201902267980547740)
- [PyTorch Metric Learning](https://kevinmusgrave.github.io/pytorch-metric-learning/)
- [FACE01 é–‹ç™ºãƒªãƒã‚¸ãƒˆãƒª](https://github.com/yKesamaru/FACE01_DEV)
- [FACE01 å­¦ç¿’æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«](https://github.com/yKesamaru/FACE01_trained_models)
- [å…¨ã¦ã®å­¦ç¿’ç‡ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒªãƒ³ã‚°ã‚’éå»ã«ã™ã‚‹Optimizer - DeNAæŠ€è¡“è¨˜äº‹](https://zenn.dev/dena/articles/6f04641801b387)
